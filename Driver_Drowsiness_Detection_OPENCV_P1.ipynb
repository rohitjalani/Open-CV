{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6MshVvTK8uX"
   },
   "source": [
    "**INSTALLING LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1662462717465,
     "user": {
      "displayName": "Rohit Jalani",
      "userId": "05649297349963855033"
     },
     "user_tz": -330
    },
    "id": "Daf0xnupULbp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "import dlib\n",
    "import imutils\n",
    "import playsound     #plays sound with single line of code\n",
    "from imutils.video import VideoStream\n",
    "import os\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "from pygame import mixer  #used for loading and playing sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGG2ThVsMx2w"
   },
   "source": [
    "**CREATING REQUIRED FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1662462720822,
     "user": {
      "displayName": "Rohit Jalani",
      "userId": "05649297349963855033"
     },
     "user_tz": -330
    },
    "id": "BMEUfjtpMgQv"
   },
   "outputs": [],
   "source": [
    "#function for playing sound\n",
    "def play_sound(path):\n",
    "  playsound.playsound(path)\n",
    "\n",
    "\n",
    "#function for finding eye aspect ratio\n",
    "#defining euclidean distance between vertical eye landmarks\n",
    "def eye_aspect_ratio(eye):\n",
    "  A = dist.euclidean(eye[1],eye[5])\n",
    "  B = dist.euclidean(eye[2],eye[4])\n",
    "\n",
    "#defining euclidean distance between horizontal eye landmarks\n",
    "  C = dist.euclidean(eye[0],eye[3])\n",
    "\n",
    "#computing aspect ratio of eyes\n",
    "  eye_asp_r = (A+B) / (2.0 * C)\n",
    "\n",
    "  return eye_asp_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6pEztCVfQhn"
   },
   "source": [
    "**INTIALIZING PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1662462720823,
     "user": {
      "displayName": "Rohit Jalani",
      "userId": "05649297349963855033"
     },
     "user_tz": -330
    },
    "id": "qysP0mXcYbFp"
   },
   "outputs": [],
   "source": [
    "#setting font for the counter\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init() #starting the mixer\n",
    "al_sound = mixer.Sound(r\"C:\\Users\\Rohit\\Desktop\\\\My DL Projects\\Driver Drowsiness Detection\\siren.WAV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1662462720823,
     "user": {
      "displayName": "Rohit Jalani",
      "userId": "05649297349963855033"
     },
     "user_tz": -330
    },
    "id": "AxinCshcZkVI"
   },
   "outputs": [],
   "source": [
    "#defining threshold\n",
    "\n",
    "#If aspect ratio falls below this threshold then the model will start counting \n",
    "#the number of frames the person has closed their eyes for\n",
    "eye_thresh = 0.25\n",
    "\n",
    "#if the number of frames having eyes closed exceeds this value , then alarm will be played\n",
    "eye_frame_check = 40\n",
    "\n",
    "#counting number of frames having aspect ratio less than eye_thresh\n",
    "counter = 0\n",
    "\n",
    "#if counter exceeds 40 then the boolean alarm_on will be updated\n",
    "alarm_on = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3589,
     "status": "ok",
     "timestamp": 1662462724408,
     "user": {
      "displayName": "Rohit Jalani",
      "userId": "05649297349963855033"
     },
     "user_tz": -330
    },
    "id": "MhKP4IDMeqFJ"
   },
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"C:\\\\Users\\Rohit\\Desktop\\\\My DL Projects\\Driver Drowsiness Detection\\shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1662462724408,
     "user": {
      "displayName": "Rohit Jalani",
      "userId": "05649297349963855033"
     },
     "user_tz": -330
    },
    "id": "F27A-aKvfNlJ"
   },
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "#the 68 landmarks are encoded inside FACIAL_LANDMARKS_IDXS\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"] #taking coordinates of left eye\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"] #taking coordinates of right eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9W-rjQKst4X"
   },
   "source": [
    "**CORE OF DROWSINESS DETECTOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes :)\n"
     ]
    }
   ],
   "source": [
    "#to get a video capture object for the camera.\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "#checking whether video capturing is started or not\n",
    "if vid.isOpened():\n",
    "    vid = cv2.VideoCapture(0)\n",
    "    print(\"yes :)\")\n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Cannot open webcam :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "error",
     "timestamp": 1662462768995,
     "user": {
      "displayName": "Rohit Jalani",
      "userId": "05649297349963855033"
     },
     "user_tz": -330
    },
    "id": "rlCKrHFcsz5_",
    "outputId": "1c676bee-88f0-4b5e-f357-98d90d1d981b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting video stream thread!!\n"
     ]
    }
   ],
   "source": [
    "print(\"starting video stream thread!!\")\n",
    "\n",
    "cv2.namedWindow(\"Driver_Drowsiness\") #window showing the output video\n",
    "\n",
    "# loop over frames from the video stream\n",
    "while (True):\n",
    "    \n",
    "    ret, frame = vid.read()    # grab and read the frames using the above created object\n",
    "    height,width = frame.shape[:2]     # resizing the height to width ratio of frames\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    # converting the frames to grayscale\n",
    "    # grayscale simplifies the algorithm and reduces computational requirements\n",
    "    \n",
    "    \n",
    "    # detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)  \n",
    "\n",
    "    for rect in rects:  # looping over each grayscale frame\n",
    "        \n",
    "        shape = predictor(gray, rect)   # predicts 68 landmarks\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        leftEye = shape[lStart:lEnd]  # ratio of euclidean distances between landmarks of left eye\n",
    "        rightEye = shape[rStart:rEnd]  #  ratio of euclidean distances between landmarks of right eye\n",
    "        leftEAR = eye_aspect_ratio(leftEye)  # EAR of left eye\n",
    "        rightEAR = eye_aspect_ratio(rightEye)  # EAR of right eye\n",
    "   \n",
    "        eye_asp_r = (leftEAR + rightEAR) / 2.0  # average of EAR of both eyes\n",
    "\n",
    "    # convex hull of an object is the minimum boundary that can completely enclose or wrap the object(or contour of that object)\n",
    "        \n",
    "        leftEyeHull = cv2.convexHull(leftEye)  # convexHull of left eye\n",
    "        rightEyeHull = cv2.convexHull(rightEye) # convexHull of right eye\n",
    "        \n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)  # drawing contours around left eye\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)  # #drawing contours around left eye\n",
    "\n",
    "        \n",
    "        if eye_asp_r < eye_thresh:  #counting number of frames when the value falls below threshold value\n",
    "            counter += 1\n",
    "\n",
    "            # if the eyes were closed for a sufficient number of frames then sound the alarm\n",
    "            if counter >= eye_frame_check:\n",
    "                \n",
    "                if not alarm_on:     # if the alarm is not on, turn it on\n",
    "                    al_sound.play()\n",
    "                            \n",
    "                    cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)  # draw an alarm notice on the frame\n",
    "                    \n",
    "        else:     # otherwise, the eye aspect ratio is not below the blink threshold, so reset the counter and alarm\n",
    "            counter = 0\n",
    "            alarm_on = False\n",
    "\n",
    "        cv2.putText(frame, \"EAR: {:.2f}\".format(eye_asp_r), (300, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)  # displaying EAR value on screen\n",
    " \n",
    "# show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF   # waitKey(0) will pause your screen because it will wait infinitely for \n",
    "                                  # keyPress on your keyboard and will not refresh the frame(cap.read()) using \n",
    "                                  # your WebCam. waitKey(1) will wait for keyPress for just 1 millisecond and\n",
    "                                  # it will continue to refresh and read frame from your webcam using cap.read().\n",
    "\n",
    "        # if the `q` key is pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZo/ohaiXMMklDinrRR/hN",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
